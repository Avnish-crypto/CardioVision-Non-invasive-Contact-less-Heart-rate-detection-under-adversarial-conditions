{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\miniconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\pc\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\pc\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import albumentations as alb\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Faces dataset contains many images with same image name. So, below is the code that we have used for renaming the images. So, that it does'nt create confusion in the further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Deep_learning'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "collection = \"Path to Actual Human_faces(Kaggle_dataset)\"\n",
    "for i, filename in enumerate(os.listdir(collection)):\n",
    "    os.rename(\"Path to Actual Human_faces(Kaggle_dataset)/\" + filename, \"Path to Actual Human_faces(Kaggle_dataset)\" + 'p'+str(i) + \".jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing the different sizes images to same size (640,480).\n",
    "The reason behind this choosing particular size is that when we captures frames using cv2, then it captures frame in this size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "image_list = []\n",
    "resized_images = []\n",
    "\n",
    "for filename in glob.glob('data\\\\temp\\\\*.jpg'): #temp stores all images(different sizes images)\n",
    "    img = Image.open(filename)\n",
    "    image_list.append(img)\n",
    "\n",
    "for image in image_list:\n",
    "    image = image.resize((640, 480))\n",
    "    resized_images.append(image)\n",
    "\n",
    "for (i, new) in enumerate(resized_images):\n",
    "    try:\n",
    "        new.save('{}{}{}'.format('data\\\\images\\\\', i+1, '.jpg')) #images folder will store all images resized to same size.\n",
    "    except:\n",
    "        print(i)\n",
    "        pass\n",
    "\n",
    "img = cv2.imread('data\\\\images\\\\1.jpg')\n",
    "print(img.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then , we manually labelled Images using Labelme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use !pip install labelme to resolve the dependecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme  #use this to label the images and save label(json file) in the Label folder.\n",
    "\n",
    "# if this does not open labelme module then use cmd and type labelme to see the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation {using albumentations module}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([\n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.4),\n",
    "                         alb.RandomGamma(p=0.2),                                          # These are the operation that we want to do on images for augmenting them.\n",
    "                         alb.RGBShift(p=0.6), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                         bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    print(os.listdir(os.path.join('data', partition, 'images')))\n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.001,0.001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "    \n",
    "        with open(label_path, 'r') as f:\n",
    "            label = json.load(f)\n",
    "\n",
    "        coords[0] = label['shapes'][0]['points'][0][0]\n",
    "        coords[1] = label['shapes'][0]['points'][0][1]\n",
    "        coords[2] = label['shapes'][0]['points'][1][0]\n",
    "        coords[3] = label['shapes'][0]['points'][1][1]\n",
    "        coords = list(np.divide(coords, [640,480,640,480]))  # albumentations accepts coordinates in the range(0-1).\n",
    "\n",
    "        try: \n",
    "            for x in range(10):\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['forehead'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
